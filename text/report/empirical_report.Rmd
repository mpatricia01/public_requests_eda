---
title: ""
subtitle: ""
author: ""
bibliography: ../bib/student_list_empirics.bib
citeproc: no
output: 
  bookdown::pdf_document2:
    toc: FALSE
    pandoc_args: !expr rmdfiltr::add_wordcount_filter(rmdfiltr::add_citeproc_filter(args = NULL))
eoutput: pdf_document
csl: ../bib/apa.csl
urlcolor: blue
fontsize: 12pt
#header-includes:
#      - \usepackage{pdflscape}
#      - \usepackage{geometry}
header-includes:
      - \usepackage{floatrow}
      - \floatsetup{capposition=top}
      - \usepackage{setspace}\onehalfspacing #\doublespacing
---

```{r setup, include=FALSE}
options(knitr.kable.NA = '')
knitr::opts_chunk$set(echo = F, message = F, warning = F)
# webshot::install_phantomjs()

library(knitr)
library(bookdown)
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(scales)
library(leaflet)
library(rgdal)

data_dir <- file.path('..', '..', 'data')

load(file.path(data_dir, 'tbl_fig_data.RData'))
zip_shp <- readOGR(file.path(data_dir, 'cb_2018_us_zcta510_500k', 'cb_2018_us_zcta510_500k.shp'))

theme_set(
  theme(
    text = element_text(size = 7),
    panel.background = element_blank(),
    plot.title = element_text(color = '#444444', size = 7, hjust = 0.5, face = 'bold'),
    axis.ticks = element_blank(),
    axis.title = element_text(face = 'bold'),
    legend.title = element_text(face = 'bold'),
    legend.key.size = unit(0.3, 'cm')
  )
)

color_palette <- c('#ba9a88', '#bbcfd7')
```


# Executive Summary

TEXT

# Introduction

In the enrollment management industry, the "enrollment funnel" is a conceptual model that describes stages in the process of recruiting students. Depicted in Figure \@ref(fig:em-funnel), the funnel begins with a large pool of "prospects" that the university would like to "convert" into customers. At each successive stage -- inquiries, applicants, admits -- the funnel narrows in order to convey the assumption of "melt" (e.g., a subset of "inquiries" will apply), ending with the cohort of enrolled students. Practically, the enrollment funnel informs interventions that increase the probability of "conversion" from one stage to another [@RN0001]. For example, emails and brochures encourage prospects and inquiries to apply. Financial aid packages -- institutional grant aid and loan guidance -- convert admits to enrolled students.

<!-- 
- [HOW TO REVISE FIGURE: MAKE PROSPECTS THE UNKNOWN GROUP OF PEOPLE YOU WANT TO APPLY TO YOUR INSTITUTION; LEADS ARE NAMES YOU PURCHASE; INQUIRIES; SPLIT INQUIRIES INTO TWO COLUMNS; INSTITUTION-AS-FIRST-CONTACT AND STUDENT-AS FIRST CONTACT; SPLIT APPLICANTS INTO TWO COLUMNS; INQUIRIES WHO APPLY VS. APPLICATION AS FIRST CONTACT]
-->


```{r em-funnel, echo = FALSE, fig.align = 'center', fig.cap = "The enrollment funnel", out.width = "45%"}
knitr::include_graphics('./../../outputs/figures/enrollment_funnel.png')
#![The enrollment funnel](assets/images/enrollment_funnel.png)
```

At the top of the enrollment funnel, universities identify leads by buying "student lists," which contain the contact information of prospective students. Sometimes referred to as “names,” student lists are the fundamental input for recruiting interventions that target individual prospects via mail, email, text, and on social media. The two dominant student list vendors are the College Board and ACT, which create student list products based on their database of standardized test takers. In fall 2021, the College Board Search and ACT Encoura student list products both charged \$0.50 per name [@RN0002; ACT?]. These products enable universities to control which prospects they purchase through the use of search filters (e.g., test score range, high school GPA range, zip code).


__Student lists and student outcomes__. Research suggests that student lists substantially affect college access outcomes -- and in turn degree completion outcomes -- for millions of students each year [@RN4739; @RN4752]. College Board encourages test takers to opt into the Colege Board Student Search Service, which enables "accredited colleges, universities, nonprofit scholarship programs, and nonprofit educational organizations" [@RN003] to "license" their contact information. @RN4739 analyzed the college access and degree completion outcomes of SAT test-takers who graduated from high school between 2015-2018, comparing students who opted into Student Search Service to students who opted out. After controlling for covariates -- including gender/sex, race/ethnicity, parental education, SAT score, and high school -- 58.0\% of students who participated in Search attended any college compared to 50.2\% of students who opted out of Search, representing a 15.5\% relative increase in the probability of college enrollment ((58-50.2)/50.2=15.5).

Figure \@ref(fig:cb-fig) -- reproduced from @RN4739 -- presents results for four-year college enrollment and degree completion. 41.1\% of students who participated in Search attended a 4-year college compared to 32.8\% of students who opted out, representing a 25.3\% relative increase in the probability of attending a 4-year college. Furthermore, change in the relative probability of attending a four-year college associated with opting in to Search out was higher for students who identified as Black (24.5%), Hispanic (34.4%), American Indian or Alaska Native (AI/AN) (23.8%), and Native Hawaiian or Pacific Islander (26.1\%) than it was for students who identified as White (21.6\%) or Asian (15.2\%). Similarly, change in the relative probability of attending a four-year college was higher for students whose parents did not attend college (40.6\%) than it was for students whose parents had a BA (18.9\%). 

```{r cb-fig, fig.height = 5, out.width = '85%', fig.cap = 'Effects of College Board Student Search Service'}
create_cb_figure <- function(categories, values, plot_title) {
  cb_fig_df <- data.frame(
    category = rep(categories, each = 2),
    subcategory = rep(c('Not Licensed', 'Gain from being Licensed'), length(categories)), 
    value = values
  )
  
  cb_fig_df$category <- factor(cb_fig_df$category, levels = categories)
  
  cb_fig_df %>%
    left_join(
      cb_fig_df %>%
        pivot_wider(id_cols = category, names_from = subcategory, values_from = value) %>%
        mutate(
          total = `Not Licensed` + `Gain from being Licensed`,
          pct_change = `Gain from being Licensed` / `Not Licensed` * 100
        ),
      by = 'category') %>% 
    ggplot(aes(x = category, y = value, fill = subcategory, width = 0.6)) +
    geom_bar(position = 'stack', stat = 'identity') +
    geom_text(aes(y = value, label = if_else(subcategory == 'Not Licensed', str_c(sprintf('%.1f', value), '%'), '')), color = '#444444', size = 2, position = position_stack(vjust = 0.5)) +
    geom_text(aes(y = total + 3, label = if_else(subcategory == 'Not Licensed', str_c('(', sprintf('%.1f', pct_change), '%)'), '')), color = '#444444', size = 2) +
    geom_text(aes(y = total + 7, label = if_else(subcategory == 'Not Licensed', str_c(sprintf('%.1f', `Gain from being Licensed`), 'pp'), '')), color = '#444444', size = 2) +
    ggtitle(plot_title) +
    xlab('') + ylab('') + 
    scale_y_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 80)) +
    scale_fill_manual(values = color_palette) +
    theme(
        plot.margin = margin(t = 0.6, unit = 'cm'),
        panel.grid.major.y = element_line(size = 0.1, color = 'gray'),
        legend.title = element_blank(),
        legend.position = 'bottom',
        legend.margin = margin(t = -0.5, unit = 'cm'),
        legend.text = element_text(margin = margin(r = 0.2, unit = 'cm'))
      ) +
      guides(fill = guide_legend(reverse = T))
}

grid.arrange(
  create_cb_figure(
    c('Overall', 'Asian', 'Black', 'Hispanic', 'AI/AN', 'HI/PI', 'White'),
    c(32.8, 8.3, 37.5, 5.7, 31.8, 7.8, 24.1, 8.3, 26.5, 6.3, 22.2, 5.8, 44.4, 9.6),
    'Enrollment'
  ),
  create_cb_figure(
    c('Overall', 'Asian', 'Black', 'Hispanic', 'AI/AN', 'White'),
    c(15.7, 4.9, 17.7, 5.0, 7.2, 2.9, 6.7, 2.9, 8.7, 4.2, 24.0, 6.7),
    'BA Completion within 4 Years'
  ),
  create_cb_figure(
    c('Overall', 'No College', 'College,\nNo BA', 'College,\nBA or Higher'),
    c(32.8, 8.3, 24.9, 10.1, 36.5, 11.0, 53.4, 10.1),
    'Enrollment'
  ),
  create_cb_figure(
    c('Overall', 'No College', 'College,\nNo BA', 'College,\nBA or Higher'),
    c(15.7, 4.9, 13.6, 6.8, 21.3, 8.5, 39.9, 10.1),
    'BA Completion within 4 Years'
  ),
  ncol = 2
)
```

\pagebreak\begingroup\fontsize{8}{12}\selectfont
_Note: AI/AN = American Indian or Alaska Native. HI/PI = Hawaiian or Pacific Islander. The sample for enrollment outcomes includes all SAT takers in the 2015–2018 high school graduation cohorts. The sample for completion outcomes is restricted to students in the 2015–2016 cohorts. Completion results are not reported for HI/PI students due to very small sample size (N=2,749), which returns imprecise estimates. Results are estimated from regressions that include student-level controls for: sex, race/ethnicity, SAT score, parental education level, last Student Search Service opt-in status, and graduation cohort and high school fixed effects. All differences between students whose names were licensed and those whose names were not licensed are statistically significant at the 1% level._
\endgroup

With respect to BA degree completion, the bottom panel of Figure \@ref(fig:cb-fig) shows that 20.6\% of students who participated in Search obtained a BA compared within four years to 15.7\% of students who opted out, representing a relative increase of 31.2\%  ((20.6-15.7)/15.7=31.2). Additionally, the relative increase in the probability of obtaining a BA within four years was higher for Black, Hispanic, and AI/AN students than it was for White and Asian students and higher for first-generation students than for students whose parents had a BA.

A similar study compared the college access outcomes of students who opted into versus opted out of ACT's Educational Opportunity Service (EOS) [@RN4752]. EOS enables accredited postsecondary institutions and scholarship organizations to license the contact information of students who opt in. After controlling for covariates -- including ACT score, number of colleges the student sent scores to, family income, parental education, degree aspirations, race/ethnicity, state -- @RN4752 found that students who opted into EOS had a 3.7 times higher likelihood (odds ratio = $3.7$) of attending college than students who opted out. A second model, which restricted the sample to students who attended college, found that students who opted into EOS had 8.7\% higher odds of attending a four-year college rather than a two-year college.

__Policy concerns__. Considering these findings, which suggest that student lists profoundly affect college access for groups who are underrepresented in higher education, the policy concern is which students are being excluded from student lists. We argue that this policy concern is primarily about student list products rather than how customers (universities) use these products.

<!-- 
CUT TEXT
Considering these findings, which suggest that student lists profoundly affect college access and especially for groups who are underrepresented in higher education, the policy concern is which students are being excluded from student lists. 

-->
Student list products exclude students in two ways. First, universities cannot purchase the contact information of prospects who are not included in the underlying database. While students who opt out of College Board Student Search Service are making a conscious decision, students cannot opt in unless they take a College Board Assessment (PSAT, SAT, AP). College Board and ACT assessments have been criticized for racial and socioeconomic bias [@RN6012; @RN6009; @RN6010; @RN004]. Test-taking rates differ substantially across race and class [CITE], leading to systematic racial and socioeconomic inequality in which prospective students are included in the underlying databases that College Board and ACT student list products pull from. About 1.5 million students from the high school class of 2021 took the SAT compared to about 2.2 million students from the high school class of 2020 [CITE](https://reports.collegeboard.org/sat-suite-program-results) and about 1.3 million student from the high school class of 2021 took the ACT compared to about 1.7 million students from the high school class of 2020. These declines were driven by the Covid Pandemic and by the growth in test-optional and test-blind admissions policies. To the extent that student lists are an important mechanism for college access, the test-optional movement may have the unintended consequence of creating a college access crisis, in which the long-term decline in test-takers leads to fewer prospective students included in College Board/ACT student list databases which causes college access to decline.

Second, student list products exclude students by creating filters that enable universities to purchase some names but not others. While universities choose filters based on their preferences, these choices are structured by what the product allows. We are concerned that several commonly used filters systematically exclude protected classes and other populations that are underrepresented in higher education (e.g., rural students). Second, the filters on student list products enable universities to target prospects based on criteria that may systematically exclude populations that are underrepresnted in higher education. For example, College Board and ACT student list products enable universities to filter prospects by zip code, which is highly correlated with race. College Board allows universities to target prospects based on their score in some set of AP exams, but which students attend high schools with widespread access to AP classes? An emerging trend is the creation of "geodemographic" filters that enable universities to select prospects based on the past behavior of students from their high school or neighborhood (e.g., how many students from this school attended an out-of-state university?) [CITE]. Student list products enable universities to explicitly search for underrepresented groups (e.g., by race/ethnicity), but when used in conjunction with additional filters (e.g., test score range, high school characteristics) these searches tend to target more privileged members of the group.

Although research sanctioned by College Board and ACT highlights the positive relationship between opting into student list products and college access [@RN4739; @RN4752; @RN4740], prior research has not examined which filter criteria universities select when purchasing student lists, what are the characteristics of purchased prospects, or the relationship between filter criteria and student characteristics. we collected data about student list purchases by issuing public records requests to public universities in five states. This report focuses on student lists purchased from College Board and addresses three research questions: 

1. Which filter criteria were selected in student lists purchased by universities in our sample?
1. What are the characteristics of prospects included in student lists purchased by universities in our sample?
1. What is the relationship between student list filter criteria and the characteristics of purchased prospects?

As a consequence of data collection challenges, our analysis sample cannot be considered a random sample. Nevertheless, as the first independent analysis of student list data, this research is an important first step towards developing a body of empirical research that informs policy discourse about regulating the student list business.

# Data Collection and Research Design

This section describes, first, the data collection for the broader project. Second, we describe the research methods for analyses of student list purchases from College Board, which are the focus of this report.

## Data Collection

__Data collection sample__.  In 2019 we received funding from the Joyce Foundation and the Kresge Foundation for a research project that would utilize public records requests to collect data about recruiting behavior from all public universities in four states, California, Illinois, Minnesota, and Texas. Broadly, we sought two types of data: off-campus recruiting visits (e.g., visit from a university admissions representative to a local high school) and student list purchases. 

IL and MN are focus states for the Joyce Foundation, while CA and TX are focus states for Kresge. The IL higher education system includes 3 universities in the University of Illinois system, 7 in the Illinois State University system, and 2 in the Southern Illinois University system. In MN, there are 5 universities in the University of Minnesota system and 7 in the Minnesota State University system. In CA, there are 9 universities in the University of California system and 23 in the California State University system. In TX, there are 8 universities in the University of Texas system, 4 in the Texas State University system, 11 in the Texas A&M University system, 4 in the University of Houston system, 2 in the University of North Texas system, 2 in the Texas Tech University system, and 4 independent Texas universities. We also collected data from Arizona State University and Northern Arizona University.

Table \@ref(tab:univ-characteristics) and Figures \@ref(fig:univ-carnegie) and \@ref(fig:univ-locale) describe the public universities in our data collection sample. A majority of the universities are master's or doctoral universities and located in urban areas. 
\newpage
<!--
- FIGURE
  - SUB-FIGURE: NUMBER OF UNIVERSITIES BY STATE AND CARNEGIE CLASSIFICATION
  - SUB-FIGURE: NUMBER OF UNIVERSITIES BY STATE AND LEVEL OF URBANIZATION (e.g., urban, suburban, rural - you decide on the variable)
- APPENDIX TABLE
  - Same as table 2 from private school chapter, with these differences:
    - add column for system name and carnegie classification; delete column for USNWR rank
    - sort by: state, system, carnegie classification, university name
-->

```{r, warning = F}
ipeds_df <- read_csv(file.path(data_dir, 'ipeds_data.csv'), na = 'NULL', col_types = c('unitid' = 'c', 'endyear' = 'c', 'satactcomp25' = 'n', 'satactcomp75' = 'n', 'freshoutstpct' = 'n', 'pgrnt_n' = 'n', 'cohortsfaef' = 'n')) %>% filter(endyear == '2017')
hd_df <- read_csv(file.path(data_dir, 'hd2017.csv'), col_types = c('UNITID' = 'c', 'SECTOR' = 'c', 'UGOFFER' = 'c', 'LOCALE' = 'c'))
carnegie_df <- read_csv(file.path(data_dir, 'carnegie_2018.csv'), col_types = c('UNITID' = 'c', 'BASIC2015' = 'c'))

univ_df <- hd_df %>% select(UNITID, INSTNM, STABBR, SECTOR, UGOFFER, LOCALE) %>% 
  left_join(carnegie_df %>% select(UNITID, BASIC2015), by = 'UNITID') %>% 
  filter(
    STABBR %in% c('CA', 'TX', 'IL', 'MN'),
    SECTOR == 1,
    UGOFFER == 1,
    !BASIC2015 %in% c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14),
    !UNITID %in% c('488800', '229337', '229300', '228644', '416801', '228653')
  ) %>% 
  left_join(ipeds_df %>% select(unitid, satactcomp25, satactcomp75, tfuginst, tfugoutst, ugftptfreshtot, freshoutstpct, pgrnt_n, cohortsfaef, ugftptfreshwhmf, ugftptfreshblmf, ugftptfreshapmf, ugftptfreshhimf, ugftptfreshalmf), by = c('UNITID' = 'unitid')) %>% 
  mutate(
    system = case_when(
      str_detect(INSTNM, 'University of California') ~ 'UC',
      STABBR == 'CA' ~ 'CSU',
      str_detect(INSTNM, 'Texas A') | UNITID %in% c('228529', '227526') ~ 'TX A&M',
      str_detect(INSTNM, 'University of Houston') ~ 'U of Houston',
      str_detect(INSTNM, 'University of North Texas') ~ 'UNT',
      str_detect(INSTNM, 'University of Texas') ~ 'U of TX',
      UNITID %in% c('222831', '229115') ~ 'TX Tech',
      UNITID %in% c('226091', '227881', '228501', '228459') ~ 'TX State U',
      STABBR == 'TX' ~ 'Indy TX',
      str_detect(INSTNM, 'University of Illinois') ~ 'U of IL',
      str_detect(INSTNM, 'Southern Illinois University') ~ 'SIU',
      STABBR == 'IL' ~ 'IL State U',
      str_detect(INSTNM, 'University of Minnesota') ~ 'UMN',
      STABBR == 'MN' ~ 'MN State U'
    ),
    locale = str_sub(LOCALE, end = 1),
    locale_text = recode_factor(
      locale,
      `4` = 'Rural',
      `3` = 'Town',
      `2` = 'Suburban',
      `1` = 'City'
    ),
    carnegie = recode_factor(
      BASIC2015,
      `-2` = 'Unknown',
      `15` = 'Doctoral Universities: Highest Research Activity',
      `16` = 'Doctoral Universities: Higher Research Activity',
      `17` = 'Doctoral Universities: Moderate Research Activity',
      `18` = 'Master\'s Colleges & Universities: Larger Programs',
      `19` = 'Master\'s Colleges & Universities: Medium Programs',
      `20` = 'Master\'s Colleges & Universities: Small Programs',
      `21` = 'Baccalaureate Colleges: Arts & Sciences Focus',
      `22` = 'Baccalaureate Colleges: Diverse Fields',
      `26` = 'Special Focus Four-Year: Other Health Professions Schools'
    )
  )

univ_df$STABBR = factor(univ_df$STABBR, levels = c('IL', 'MN', 'CA', 'TX'))
univ_df$system = factor(univ_df$system, levels = c('U of IL', 'IL State U', 'SIU', 'UMN', 'MN State U', 'UC', 'CSU', 'U of TX', 'TX State U', 'TX A&M', 'U of Houston', 'UNT', 'TX Tech', 'Indy TX'))
```

```{r univ-characteristics}
univ_df %>%
  mutate(
    satactcomp25 = if_else(is.na(satactcomp25), '', prettyNum(round(satactcomp25, 0), ',')),
    satactcomp75 = if_else(is.na(satactcomp75), '', prettyNum(round(satactcomp75, 0), ',')),
    tfuginst = str_c('$', prettyNum(sprintf('%.2f', tfuginst), ',')),
    tfugoutst = str_c('$', prettyNum(sprintf('%.2f', tfugoutst), ',')),
    freshoutstpct = if_else(is.na(freshoutstpct), '', str_c(sprintf('%.1f', freshoutstpct * 100), '%')),
    pgrnt_p = if_else(is.na(pgrnt_n), '', str_c(sprintf('%.1f', pgrnt_n / cohortsfaef * 100), '%')),
    pctfreshwh = if_else(ugftptfreshtot == 0, '', str_c(sprintf('%.1f', ugftptfreshwhmf / ugftptfreshtot * 100), '%')), 
    pctfreshbl = if_else(ugftptfreshtot == 0, '', str_c(sprintf('%.1f', ugftptfreshblmf / ugftptfreshtot * 100), '%')), 
    pctfreshhi = if_else(ugftptfreshtot == 0, '', str_c(sprintf('%.1f', ugftptfreshhimf / ugftptfreshtot * 100), '%')), 
    pctfreshap = if_else(ugftptfreshtot == 0, '', str_c(sprintf('%.1f', ugftptfreshapmf / ugftptfreshtot * 100), '%')), 
    pctfreshal = if_else(ugftptfreshtot == 0, '', str_c(sprintf('%.1f', ugftptfreshalmf / ugftptfreshtot * 100), '%')),
    ugftptfreshtot = if_else(ugftptfreshtot == 0, '', prettyNum(ugftptfreshtot, ','))
  ) %>% 
  select(STABBR, system, INSTNM, carnegie, satactcomp25, satactcomp75, tfuginst, tfugoutst, ugftptfreshtot, freshoutstpct, pgrnt_p, pctfreshwh, pctfreshbl, pctfreshhi, pctfreshap, pctfreshal) %>% 
  arrange(STABBR, system, desc(carnegie), INSTNM) %>% 
  kable(booktabs = F, col.names = c('State', 'System', 'University', 'Carnegie', '25th pctl SAT/ACT', '75th pctl SAT/ACT', 'In-state tuition', 'Out-of-state tuition', '# Freshmen' , '% Out-of-state freshmen', '% Pell', '% White', '% Black', '% Latinx', '% Asian/PI', '% Non-resident alien'), caption = 'University characteristics') %>%
  collapse_rows(columns = 1:2, latex_hline = 'custom', custom_latex_hline = 1:2, valign = 'middle') %>%
  kable_styling(latex_options = 'scale_down')
```

```{r univ-carnegie, fig.height = 2, fig.cap = 'University by carnegie classification'}
univ_df %>% 
  group_by(STABBR, carnegie) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = count, y = STABBR, fill = carnegie, width = 0.6)) +
  geom_bar(position = 'stack', stat = 'identity', alpha = 0.6) +
  geom_text(aes(x = count, label = count), color = '#555555', size = 2, position = position_stack(vjust = 0.5)) +
  geom_text(data = univ_df %>% group_by(STABBR) %>% summarise(total = n()), aes(x = total + 1.8, y = STABBR, label = str_c('N=', total), fill = NULL), color = '#444444', size = 2) +
  xlab('') + ylab('') +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 37)) +
  scale_fill_brewer(palette = 'Spectral', direction = -1, name = 'Carnegie classification') +
  theme(
    axis.text.x = element_blank()
  ) +
  guides(fill = guide_legend(reverse = T))
```

\bigskip

```{r univ-locale, fig.height = 2, fig.cap = 'University by locale'}
univ_df %>% 
  group_by(STABBR, locale_text) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = count, y = STABBR, fill = locale_text, width = 0.6)) +
  geom_bar(position = 'stack', stat = 'identity', alpha = 0.6) +
  geom_text(aes(x = count, label = count), color = '#555555', size = 2, position = position_stack(vjust = 0.5)) +
  geom_text(data = univ_df %>% group_by(STABBR) %>% summarise(total = n()), aes(x = total + 1.2, y = STABBR, label = str_c('N=', total), fill = NULL), color = '#444444', size = 2) +
  xlab('') + ylab('') +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 37)) +
  scale_fill_brewer(palette = 'YlGnBu', direction = -1, name = 'Locale') +
  theme(
    axis.text.x = element_blank()
  ) +
  guides(fill = guide_legend(reverse = T))
```

__Public records requests__. In 20XX, we signed an agreement with the Lawyers' Committee for Civil Rights Under Law (LCCR) to partner on the data collection. Although We had experience issuing public records requests from a previous data collection about off-campus recruiting visits by public research universities, the greater scale, complexity, and sensitivity of this project motivated us to find a partner with greater legal expertise. LCCR was created by the Kennedy Administration to leverage private sector legal expertise towards civil rights. LCCR typically operates by connecting projects with the pro bono efforts of corporate law firms. 

LCCR recruited firms to work on our project. Several firms expressed initial interest. Unfortunately, these firms withdrew following conflict of interest checks. However, LCCR generously allocated time of an internal staff attorney towards our project. Additionally, one firm offered to help us collect data from Arizona public universities. Although Arizona was not part of the funded project, we gratefully accepted.

We began issuing public records requests in February 2020, following several months of planning and pilot requests. We issued one records request letter for each public university. An example records request letter can be found HERE [ADD LINK]. Each request letter asked for data about off-campus recruiting visits and student list purchases for the purpose of undergraduate recruiting, which were made from August 2016 to the present. For each student list purchase from a student list vendor, we requested two related pieces of data: the order summary, which specifies search criteria for the student list purchase; and the de-identified prospect-level list produced from the search criteria. 

As such, we conceived of our data collection as requesting three types of information: (1) off-campus recruiting visits; (2) student list order summaries; and (3) de-identified student list data. Each request letter included examples of desired off-campus recruiting visit data [LINK], student list order summary data [LINK], and de-identified student list data [LINK] as attachments.

__Data collection challenges and successes__. [ALL/MOST OF THIS SUB-SECTION WILL GO IN AN APPENDIX IN TICAS/ACCEPT REPORT; MAYBE KEEP IN MAIN TEXT FOR REPORT TO FOUNDATIONS] TABLE(S)/FIGURE(S) summarizes the success to date of our data collection efforts and Appendix X reports the status of data collection for each university. We received usable quantitative off-campus recruiting visit data from X universities, usable student list order summary data from X universities, and usable de-identified student list data from X universities. [CRYSTAL - CREATE TABLES AND FILL IN PARAGRAPH TEXT]

Using public records requests to collect quantifiable data is difficult under the best of circumstances. Unfortunately, we started collecting data just as Covid-19 emerged. Several additional challenges -- some foreseeable and tractable and others not -- made data collection difficult. State public records request laws generally require public entities to redact records that contain sensitive personal information but do not require public entities to create new records. Consider a prospect-level student list stored by a public university in a spreadsheet format. Removing personally identifiable information (e.g., fields for name, mailing address, email address) is part of the redaction process. By contrast, if information about off-campus recruiting visits stored in old emails or an antiquated calendar system, compiling these records would be considered creating new records rather than redaction. This turned out to be the most common reason we did not obtain off-campus recruiting visit data.

For student list purchases, an additional complication is that universities may purchase lists from multiple vendors. When we initiated data collection, the three largest vendors were College Board, ACT, and the National Research Center for College and University Admissions (NRCCUA), which had just been purchased by NRCCUA. In subsequent communication with universities, we narrowed our student list purchase requests to these three vendors.

Many public universities outsourced student list purchases to an enrollment management consulting firm, which created several challenges. Often, employees at these universities often lacked knowledge about student list purchases and were unfamiliar with the records we requested. Employee turnover often exacerbated this lack of institutional knowledge. Second, these universities often did not have the requested order summaries and student lists in their possession. Third, enrollment management consulting firms posed another barrier. The information firms regularly sent to universities was too aggregate and firms were unwilling to help provide the original records we sought. 

In response to early data collection challenges, we created a "vendor portal document" [LINK]. This document provided detailed instructions -- separately for College Board, ACT, and NRCCUA -- for how to log-in to the online portal, obtain the order summary for each student list purchase, obtain student list data for each purchase, and how to de-identify these data. Unfortunately, this document was less effective for ACT and NRCCUA than it was for College Board. ACT released the Encoura platform in 20XX, following its 2018 acquisitionn of NRCCUA. The online portals that provided access to students lists purchased from the legacy ACT and NRCCUA student list products were continued. Furthermore, whereas the College Board portal gave customers access to student lists purchased in the last X [CRYSTAL] years, the Encoura portal provided access to purchases within the previous 12 months. 

The most common data collection challenges were universities not replying to the request or denying the request based on questionable legal grounds. We learned that obtaining these data depends on treating each university as a protracted negotiation -- often several negotiations -- that requires sustained effort and some degree of leverage. Even with time from a LCCR staff attorney, we lacked sufficient capacity for sustained negotiations with each university and we lacked a stick that commanded university attention.

In Spring 2021, LCCR successfully recruited three law firms to represent data collection efforts in Illinois, Minnesota, and California, respectively. However, we were unable to obtain representation for Texas. The firms produced legal research that demonstrated the legitimacy of our requests and dismantled common rationales for denial (e.g,. "trade secrets"). Next, the firms systematically engaged universities, often directly engaging the university or system-level general counsel, who then directed the public records office and other offices to cooperate with our request. Firm representation substantially increased the number of successful requests. However, many universities provided legitimate reasons for not providing one or more requested data elements (e.g., records no longer exist, not required to create new records). Some universities denied request elements on grounds that firms believed lacked legal merit. However, we made a collective decision not pursue litigation.

In hindsight, we identify several changes may benefit efforts to collect public records in the enrollment management space. First, many universities were understandably overwhelmed by a request for several complicated, esoteric data sources. We could have issued several narrower requests rather than a single multi-aceted request. Related, our request for student list data should have proceeded in two stages: first, requesting contracts with a specific set of student list vendors over a time period; and, second, for each contract received, issuing a separate records request for the student list order summaries de-identified student lists associated with that contract. Third, underestimated the extent to which university personnel were unfamiliar with student list purchases and also the number of universities that outsourced student list purchases to a consulting firm. We should have created the "vendor portal" instructions document at the beginning of the data collection process.

__Data processing__. Records received from universities were visually inspected to check whether they contained the requested fields and data structure. If not, we communicated the problems to the university and asked for revised records. Records that passed visual inspection were processed. For the current analysis, only College Board data were processed as they are the most common and easily obtained. The order summaries were generally provided as PDF files and were parsed using Python, a general-purpose programming language. The student-level lists were imported and cleaned using the statistical programming language R, and all subsequent analysis of the order summaries and lists were done in R as well.

## Research Design

__Analysis sample__. Given that prior research has not analyzed student list purchases, this report restricts analyses to student lists purchased from College Board in order to keep results as simple as possible, with the idea that future analyses will incorporate lists purchased from ACT. Table \@ref(tab:received-data) shows the number of public universities in our data collection sample that provided usable data about (1) student list order summaries and (2) de-identified student lists purchased from College Board. [CRYSTAL ADD TEXT SUMMARIZING TABLE]. Our analysis sample consists of X universities that provided usable data about student lists purchased from College Board, including X universities that provided both order summary and student list data, X universities that only provided order summary data, and X universities that only provided student list data.

To what extent are the student list purchases we analyze representative of student lists purchased by universities in our analysis sample? Universities may purchase student lists from several different vendors but College Board and ACT dominate the market. In CA and TX, the majority of test-takers take the SAT [CITE]. Historically, most IL test-takers took the ACT, but in 2016 the state signed a contract with College Board for all IL juniors to take the SAT [CITE](https://www.chicagotribune.com/news/ct-illinois-chooses-sat-met-20160211-story.html). In MN, the vast majority of test-takers take the ACT. These state-by-state differences suggest that students lists purchased from College Board will not be representative of all student lists purchases, particularly for MN public universities. Another issue is that some universities provide incomplete data about student lists purchased from College Board during the requested time period. When we received the order summary for a particular purchase but not the de-identified student list -- or vice-versa -- we have direct evidence of incomplete data. However, we usually cannot assess whether the data we received identifies the full set of student lists purchased from College Board.

Our inability to obtain data from all universities creates external validity concerns. Ideally, our analysis dataset includes all College Board student lists for the entire population of public universities in our data collection sample, or at least a random sample of these universities. Unfortunately, our analysis sample cannot be considered a random sample. Moreover, we suspect that non-response was systematically related to factors of substantive interest. For example, we were less successful obtaining records from universities that outsourced student list purchases to consulting firms. In turn, response bias affects external validity. Based on our results, we cannot make inferences about the population of universities in the four data collection states. Nor can we make inferences about the broader population of US public universities.

<!--
- WHAT TO SHOW
  - NUMBER OF UNIVERSITIES THAT DID AND DID NOT PROVIDE USABLE ORDER SUMMARY DATA
  - NUMBER OF UNIVERSITIES THAT DID AND DID NOT PROVIDE USABLE STUDENT LIST DATA
  - NUMBER OF UNIVERSITIES THAT DID AND DID NOT PROVIDE **BOTH** USABLE ORDER SUMMARY DATA AND USABLE STUDENT LIST DATA
- ORGANIZED BY [MAYBE A FIGURE WITH THREE SEPARATE PANELS? USE YOUR DISCRETION:
  - STATE
  - STATE AND CARNEGIE CLASSIFICATION
  - STATE AND LEVEL OF URBANIZATION

Table/Figure X shows the number of lists and the number of prospects purchased by universities in our analysis sample [CRYSTAL ADD TEXT] [SPECIFICATIONS FOR FIGURE (USE YOUR DISCRETION!)]

- WHAT DATA TO SHOW
  - NUMBER OF ORDERS (REGARDLESS OF WHETHER WE HAVE STUDENT LIST DATA)
  - NUMBER OF ORDERS WHERE WE HAVE STUDENT LIST DATA
  - NUMBER OF PROSPECTS PURCHASED (REGARDLESS OF WHETHER WE HAVE THE ORDER SUMMARY)
  - NUMBER OF PROSPECTS PURCHASED WHERE WE HAVE THE ORDER SUMMARY
- SHOW DATA BY:
  - STATE AND CARNEGIE CLASSIFICATION 
- SUB-FIGURES? 
  - USE YOUR DISCRETION
-->

```{r received-data}
appendix_df <- univ_df %>% 
  select(INSTNM, STABBR, system, carnegie, locale_text) %>% 
  mutate(
  'num_received_summary' = rep_len(c(T, F), 91),
  'num_not_received_summary' = rep_len(c(F, T), 91),
  'num_received_list' = rep_len(c(T, F), 91),
  'num_not_received_list' = rep_len(c(F, T), 91),
  'num_received_both' = rep_len(c(T, F), 91),
  'num_not_received_both' = rep_len(c(F, T), 91)
) 

appendix_df %>% 
  group_by(STABBR) %>% 
  summarise(
    'num_received_summary' = sum(num_received_summary),
    'num_not_received_summary' = sum(num_not_received_summary),
    'num_received_list' = sum(num_received_list),
    'num_not_received_list' = sum(num_not_received_list),
    'num_received_both' = sum(num_received_both),
    'num_not_received_both' = sum(num_not_received_both)
  ) %>% 
  kable(booktabs = T, col.names = c('State', '# received order summary', '# no order summary', '# received list', '# no list', '# received both', '# did not receive both'), align = rep('c', 7), caption = 'Summary of data received') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(latex_options = 'scale_down')
```

```{r purchased-data}
data.frame(
  orders_total = orders_df %>% nrow(),
  orders_with_list = orders_df %>% left_join(lists_df_summary, by = c('order_num' = 'ord_num')) %>% filter(!is.na(n)) %>% nrow(),
  prospects_total = prettyNum(sum(lists_df_summary$n), ','),
  prospects_with_order = prettyNum(sum((lists_df_summary %>% filter(!is.na(ord_num)))$n), ',')
) %>% 
  kable(booktabs = T, col.names = c('# orders total', '# orders with list', '# prospects total', '# prospects with order'), align = rep('c', 4), caption = 'Summary of orders and prospects purchased') %>% 
  row_spec(0, bold = T) %>% 
  kable_styling(position = 'center')
```

```{r purchased-orders-carnegie, fig.height = 2, fig.cap = 'Summary of orders purchased by carnegie classification'}
lists_df_summary %>% 
  mutate(has_order = !is.na(ord_num)) %>% 
  group_by(has_order, univ_state, univ_c15basic) %>% 
  summarise(count = sum(n)) %>% 
  mutate(
    has_order = factor(has_order, levels = c(T, F)),
    univ_state = factor(as.character(univ_state), levels = c('TX', 'CA', 'MN', 'IL')),
    univ_c15basic = as_factor(univ_c15basic),
    carnegie = recode_factor(
      univ_c15basic,
      "Doctoral Universities: Highest Research Activity" = "Research Extensive",
      "Master's Colleges & Universities: Larger Programs" = "Master's",
      "Master's Colleges & Universities: Medium Programs" = "Master's",
      "Baccalaureate Colleges: Diverse Fields" = "Baccalaureate"
    )
  ) %>% 
  ggplot(aes(x = count, y = univ_state, fill = carnegie, alpha = has_order, width = 0.6)) +
  geom_bar(position = 'stack', stat = 'identity') +
  xlab('Number of prospects') + ylab('') +
  scale_x_continuous(labels = label_number(suffix = 'K', scale = 1e-3), expand = expansion(mult = c(0, 0.05)), limits = c(0, 855000)) +
  scale_fill_brewer(palette = 'YlGnBu', direction = -1, name = 'Carnegie classification') +
  scale_alpha_manual(values = c(0.6, 0.3), name = 'Has order summary') +
  guides(fill = guide_legend(reverse = T, order = 1, override.aes= list(alpha = 0.6)))
```

```{r purchased-prospects-carnegie, fig.height = 2, fig.cap = 'Summary of prospects purchased by carnegie classification'}
orders_df %>% 
  left_join(lists_df_summary %>% select(ord_num, n), by = c('order_num' = 'ord_num')) %>%
  mutate(has_list = !is.na(n)) %>% 
  group_by(has_list, univ_state, carnegie) %>% 
  summarise(count = n()) %>% 
  mutate(
    has_list = factor(has_list, levels = c(T, F)),
    univ_state = factor(as.character(univ_state), levels = c('TX', 'CA', 'MN', 'IL')),
    carnegie = factor(carnegie, levels = c("Research Extensive", "Master's", "Baccalaureate"))
  ) %>% 
  ggplot(aes(x = count, y = univ_state, fill = carnegie, alpha = has_list, width = 0.6)) +
  geom_bar(position = 'stack', stat = 'identity') +
  xlab('Number of orders') + ylab('') +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 301)) +
  scale_fill_brewer(palette = 'YlGnBu', direction = -1, name = 'Carnegie classification') +
  scale_alpha_manual(values = c(0.6, 0.3), name = 'Has list') +
  guides(fill = guide_legend(reverse = T, order = 1, override.aes= list(alpha = 0.6)))
```

__Research questions and analyses__. Choices about research questions were informed by the limitations of our analysis sample and by substantive considerations. We cannot make statements about university behavior that extends beyond our analysis sample. Assuming our data is representative of lists purchased by universities in our sample, 
we can make statements about the College Board student lists purchased by universities in our analysis sample. This reasoning suggests treating our sample as a multiple case study [@RN4116]. The behaviors observed in our sample identify behaviors that exist in the population of public public universities, but not the prevalence of these behaviors in the population.


More substantively, during the course of data collection we realized that research should focus on the student list products themselves rather than the behavior of customers (universities) who buy the product. while universities choose which names to purchase, these choices are structured by what the product allows. Systematic inequality in purchased versus excluded names is a function of (A) which prospective students are included in the underlying data base and (B) the set of filters that universities can utilize to select prospects and finally (C) university choices about which filters to select. Prospective students who do not take College Board assessments are excluded from College Board lists. College Board filters encourage customers to purchase prospects based on their score ranges in SAT, PSAT, and AP assessments, but which students attends high schools with widespread access to AP classes? Geographic filters additionally enable to customers to filter prospects based zip code. which is highly correlated by race. More recently, College Board has created "geodemographic" filters that target prospects based on the recent college-going behaviors of nearby peers. These considerations suggest analyses that investigate the relationship between the filters chosen for a particular student list purchase and who is included in the resulting student list.

The empirical analyses presented in this report are guided by three research questions, which focus on student lists purchased from College Board:

1. Which filter criteria were selected in student lists purchased by universities in our sample?
1. What are the characteristics of prospects included in student lists purchased by universities in our sample?
1. What is the relationship between student list filter criteria and the characteristics of purchased prospects?

In RQ1 the unit of analysis is the order or university-order. Analyses allow us to make statements about how orders vary -- within-university and between-university variation -- for universities in our sample. In RQ2 the unit of analysis is university-prospect. Analyses allow us to make statements about the characteristics of prospects targeted by universities in our sample. In RQ3 the unit of analysis is order-prospect. Analyses allow us to make statements about the relationship between filter criteria and prospect characteristics that extend to lists purchased by any university that select similar filter criteria.

Empirical analyses consist of simple descriptive statistics presented in tables, figures, and maps. For each research question, analyses are anchored by a small set of tables or figures that present results for the entire analysis sample. Next, we present analyses of selected universities, purchases and/or localities that convey commonly observed or thematically important patterns, with a focus on the nexus between race, class, and geography. For RQ2 and RQ3, we contextualize the characteristics of purchased prospects by showing the characteristics of one or more comparison groups (e.g., all high school graduates in the metropolitan area).

__Secondary data__. Analyses incorporate several secondary data sources. Integrated Postsecondary Education Data System (IPEDS) data provides characteristics of universities in the analysis sample. NCES Common Core of Data (CCD) and Private School Universe Survey (PSS), respectively, provides data about U.S. public and private high schools. The Census American Community Survey (ACS) provide data about community characteristics. We use zip-code level data from ACS 5-year estimates. [OTHER SECONDARY DATA SOURCES TO ADD?]


# Results  

## Characteristics of Student List Purchases 

### Total Orders and Number of Prospects

Figure \@ref(fig:orders-purchased) presents the 486 total orders analyzed in this report by university type and total students purchased. The 486 orders were purchased across 12 universities. The six master's universities in the study made the majority of order purchases (N=307), while research universities made 178 orders and the only baccalaureate university in the study made one order. 

The number of total prospects purchased within each order varied widely. Across all 486 orders, the median number of prospects purchased per order was 3,067, whereas the mean was 950 (sd=5,619). Despite making fewer total orders than master's universities, research universities on average purchased nearly double the number of students per order (4,269 versus 2,382). The only baccalaureate college in the study purchased 5,539 prospects in their one College Board order.

```{r orders-purchased, fig.height = 3, fig.cap = 'Orders purchased by carnegie classification'}
orders_fig_totals %>% 
  ggplot(aes(x = reorder(university, -total_students), y = total_students, fill = as_factor(carnegie), width = 0.8)) +
  geom_bar(stat = 'identity', alpha = 0.6) +
  geom_text(aes(label = str_replace(total_orders_st, '^1 orders', '1 order'), y = total_students + 2000), vjust = 0, size = 2, fontface = 'bold') +
  xlab('') + ylab('Total students') +
  scale_y_continuous(labels = label_number(suffix = 'K', scale = 1e-3)) +
  scale_fill_brewer(palette = 'YlGnBu', name = 'Carnegie classification') +
  theme(
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank()
  )
```

### Frequency of Filters Used

Filters used to select prospect lists varied across academic criteria (e.g., GPA, PSAT, SAT, academic rank, AP Score), geographic location (e.g., zip code, state, segment, core based statistical area, geomarket, international), and demographic characteristics (e.g., high school graduation class, race/ethnicity, gender). Some geographic filters are metrics created by the College Board. For example, segment filters come from the College Board’s “Segment Analysis Service” which merges demographic, geographic, and academic data on SAT test takers to create "geodemographic profiles" for college-bound students (The College Board, 2011, p. 3). These profiles are created at the neighborhood-level and at the school-level. Geomarket filters are also created by the College Board within Enrollment Management Services, which uses information about SAT score senders from the past five admissions cycles within a specific geographic locality (e.g., counties, metropolitan areas, cities) to make projections about high high school graduates in the area. 

Figure \@ref(fig:orders-filters) shows how often filters were used across all orders. All 486 orders filtered by high school graduation class. The most frequently used filters include GPA (94%), PSAT scores (60%), zip code (57%), and SAT scores (56%). About two in every five orders also filtered by state. Only a subset of orders filtered by race/ethnicity (15%), academic rank (10%), gender (5%), segment (5%), AP score (5%), core based statistical area (3%), geomarket (3%), and international (3%).

```{r orders-filters, fig.height = 3, fig.cap = 'Filters used in order purchases'}
orders_filters1 %>% 
  ggplot(aes(x = reorder(filters, V1), y = V1)) +
  geom_bar(stat = 'identity', fill = '#d2c8bc') +
  geom_text(aes(label = percent), hjust = -0.1, colour = 'black', size = 2, fontface = 'bold') +
  xlab('') + ylab('Number of orders') +
  scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
  coord_flip()
```

The three most commonly used academic filters (GPA, PSAT, SAT) were used by specifying a low and/or high threshold. Across the 464 orders using GPA, low thresholds ranged from A to C+, with the majority of orders using a low of B- (50%) or B (15%). All orders using GPA orders indicated a high threshold of A+. For orders using PSAT lowest score thresholds, 30% indicated less than 1000, 18% indicated 1000-1100, 19% indicated 1110-1200, 17% indicated 1210-1300, 7% indicated 1310-1400, and 9% indicated 1410-1500. For orders using PSAT highest score thresholds, 13% indicated less than 1000, 12% indicated 1000-1100, 26% indicated 1110-1200, 19% indicated 1210-1300, 11% indicated 1310-1400, and 19% indicated 1410-1500. ^[Old PSAT scores were converted to equivalent thresholds for new format: STILL NEED TO DO THIS]. Similar thresholds and percentages were evident for orders that used SAT as a filter. Low SAT thresholds across orders were 17% for less than 1000, 30% for 1000-1100, 21% for 1110-1200, 28% for 1210-1300, 10% for indicated 1310-1400, and 6% for 1410-1500. High SAT thresholds across orders were 9% for 1000-1100, 12% for 1110-1200, 18% for 1210-1300, 5% for indicated 1310-1400, 21% for 1410-1500, and 35% indicated scores greater than 1500+.

```{r orders-gpa}
table_gpa %>% 
  mutate(
    pct_low = str_c(pct_low, '%'),
    pct_high = str_c(pct_high, '%')
  ) %>% 
  kable(booktabs = T, col.names = c('GPA', '# low', '% low', '# high', '% high'), align = c('l', rep('c', 4)), caption = 'Filter by GPA') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(position = 'center')
```

PSAT and SAT score thresholds were consistently higher for orders by research universities in comparison to master's universities. The average low PSAT threshold score for research university orders was 1275 (about 90th percentile) versus 1034 for master's universities (about 50th percentile). Similar patterns were evident for SAT score thresholds. The average low SAT score threshold for research university orders was 1247 versus 1110 for orders by master's universities. 


Zip code, state, and segment were the most commonly used geographical filters used across all orders. While we can account for the number of orders that filtered by zipcodes (N=278), we can only analyze patterns for the 208 orders from universities that provided the list of 3-digit zipcodes filtered by. ^[The other 70  orders indicated a zip code filter; however, the actual zipcodes used to filter order lists were not provided to us after multiple requests]  These orders were made by two master's universities, primarily for in-state orders. Figure \@ref(fig:orders-zip) shows the three-digit zip code filters used across these orders.  The majority of orders (113 of 118) using zip code filters by the first master's university were to zip codes exclusively in the state where the university resides. The remaining 5 orders included in-state and neighboring state zip codes. Orders using zip code filters by the second master's university reveal similar patterns, except the majority of orders included a mix of in-state and neighboring state zip codes  (70 of 108). 

```{r orders-zip, fig.height = 4, fig.cap = 'Filter by 3-digit zip code'}
zip_shp_purchased <- subset(zip_shp, str_detect(ZCTA5CE10, str_c('^', orders_df$zip_code %>% na.omit() %>% unique() %>% str_split('\\|') %>% unlist(), collapse = '|')))

leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(data = zip_shp_purchased, stroke = F, fillOpacity = 0.8, smoothFactor = 0.2, color = 'gray')
```

Figure \@ref(tab:orders-state) shows states that were selected across the 170 orders using the filter. Generally, multiple-state filters were used across out-of-state prospect orders, whereas orders that filtered by only a single state were used for purchasing in-state prospects. 

```{r orders-state}
orders_df %>%
  filter(nchar(state_name) > 0) %>% 
  mutate(
    state_name = case_when(
      str_detect(state_name, '\\|') ~ 'Multi-state', 
      state_name == 'California' ~ 'CA', 
      state_name == 'Texas' ~ 'TX', 
      state_name == 'Illinois' ~ 'IL', 
      T ~ state_name
    )
  ) %>% 
  group_by(univ_state, state_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  kable(booktabs = T, col.names = c('University state', 'Purchased state(s)', 'Count'), align = rep('c', 3), caption = 'Filter by state') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(position = 'center')
```

The twenty two orders using segment filters were made by two public research universities in the sample. Figure \@ref(fig:orders-cluster) shows which neighborhood and high school segments were used across these orders and the characteristics of these segments. One university made 21 of the 22 orders using segment filters, and all 21 orders followed the same patterns of segments. These 21 orders filtered for 10 different neighborhood clusters (51, 53, 58, 60, 61, 63, 69, 70, 73, and 78). ONE SENTENCE ABOUT PATTERNS in CHARACTERISTICS OF THESE NEIGHBORHOODS. Orders also filtered by high school segment clusters 58, 63, 64, 65, 66, 68, 69, 70, 73, 75, and 79. ONE SENTENCE ABOUT PATTERNS IN CHARACTERISTICS OF THESE HIGH SCHOOLS. ONE SENTENCE ON SEGMENT ORDER BY NORTHEASTERN UNVIERSITY?

```{r orders-cluster, out.width = '100%', fig.cap = 'Filter by neighborhood and high school segments', fig.show = 'hold', fig.align = 'center'}
knitr::include_graphics(c(file.path(data_dir, 'cluster_EN.png'), file.path(data_dir, 'cluster_HS.png')))
```

Figure \@ref(fig:orders-filters) also shows that 75 (15%) and 24 (5%) of the 486 orders used a filter for race/ethnicity and gender, respectively. Most of the 75 orders using race/ethnicity filters specified multiple race/ethnicity groups. This includes 28 orders that filtered by Black, Native American, or Latinx prospects; 19 orders that filtered for Asian or White prospects; 7 orders that filtered for Native American or Latinx prospects; and 7 orders that filtered for Asian, White, or other race. The remaining orders filtered for only one race/ethnicity group, include 2 orders filtering for Native American prospects (American Indian, Alaska Native, and/or Native Hawaiian or Other Pacific Islander), 1 order filter for Black prospects, and 11 orders filtering for Latinx prospects. For the 24 orders using gender filters, 75% indicated female prospects and 25% indicate Male prospects. 


### Combination of Filters

Universities in the study used 39 different combinations of filters to purchase prospects. The ten most commonly used combination of filters, which account for nearly 80% of all orders, are presented in Table \@ref(tab:orders-filter-combos). More than half of all orders analyzed used a combination of high school graduation class, zip code, GPA, and PSAT and/or SAT scores to filter prospect lists. This includes 143 orders (29%) that used PSAT scores, 107 orders that used SAT scores (22%), and 28 orders that used both PSAT and SAT (5%) in addition to graduation class, zip code, and GPA. Other orders used a similar pattern of filters except for using state geographic filters instead of zip code, including 18 orders using PSAT scores and another 18 orders using SAT scores. 

```{r orders-filter-combos}
df_0 %>% 
  kable(booktabs = T, col.names = c('Filters', 'Count'), align = c('l', 'c'), caption = 'Filter combos used in order purchases') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(position = 'center')
```

About 8% of orders (39 of 486) used high school graduation class, state, sat, psat, gpa, and class rank filters while specifying for the race/ethnicity of prospects. The second most commonly used filter combination that specified the race/ethnicity of prospects includes 16 orders that used it in combination with graduation class, state, PSAT, and GPA filters. 

The remaining combinations followed similar general patterns in targeting both the academic and geographical characteristics of prospects as the top combinations described above; however, they used other types of filters (e.g., gender, AP scores, segment, geomarket). Thirteen orders used graduation class, state, SAT, PSAT, and GPA filters in combination with segment and gender. Orders that used the segment filter used both neighborhood and high school clusters. For example, one specific order included a filter for census tracts assigned to neighborhood cluster 51, but further filtered by only including prospects from schools assigned to high school clusters 65, 68, 70, and 79 were included. 

Eleven orders used graduation class, state, GPA in combination with APscores. AP score filters tended to be grouped into "fields" and varied across score thresholds. Most orders targeted prospects scoring from 3-5 on AP exams in either STEM fields (e.g., Physics, Calculus, Biology, Chemistry, Computer Science) or Humanities and Fine Arts (e.g., Spanish, French, Art History, Music Theory), although some STEM orders filtered for prospects scoring a 4 or 5 on their AP exans. 

Lastly, nine orders used graduation class, SAT, and geomarket. These orders filtered for geomarkets within Texas and Louisiana. Louisiana geomarket orders targeted prospects in the Baton Rouge and Shreveport areas. Texas geomarkets filtered for include but are not limited to the Dallas/Ft. Worth areas, Central Gulf Coast, Wharton County, Victoria County, City of San Antonio, Southwest Houston Metropolitan Area, Brazos and Trinity Valley, Austin and Central Texas, Galveston area, East Texas. 


## Characteristics of Prospects 

Our analysis on the characteristics of prospects purchased by universities includes 388 orders resulting in 1,967,352 prospects. Figure \@ref(fig:prospects-count) shows the total number of prospects by domestic versus international status. Of the nearly 2 Million prospects purchased, 95% of them were domestic students. 

Figure \@ref(fig:prospects-count) also shows the number of domestic prospects purchased by in-state versus out-of-state and by institutional type. Overall, the majority of prospects purchased across all orders by all institutions in the study were in-state students (58%). However, the percent of in-state versus out-of-state prospects varied across institutional type. Research universities purchased more students overall and a greater proportion of out-of-state students than master's universities. For example, research universities in the study purchased more than 1.2 Million prospects of which 62% were out-of-state. In comparison, master's universities purchased less than 650,000 prospects of which only 4% were out-of-state students. 

Below we also describe the racial, economic, and schooling characteristics of domestic prospect lists across institutional type and in-state versus out-of-state. The last sub-section then describes the characteristics of international prospects purchased.

```{r prospects-count, fig.height = 2.5, fig.cap = 'Number of prospects purchased'}
df_rq2a_counts <- df_rq2a %>% 
  filter(row_subj == 'Total N') %>% 
  select(all_domestic, research_univ_instate, research_univ_outofstate, regional_univ_instate, regional_univ_outofstate) %>% 
  t()

df_rq2a_counts <- data.frame(df_rq2a_counts, row.names = rownames(df_rq2a_counts)) %>% 
  rownames_to_column(var = 'count_type') %>% 
  dplyr::rename(count = df_rq2a_counts) %>% 
  mutate(loc_type = 'Domestic') %>% 
  rbind(c('all_domestic', df_int2$n[[2]], 'International')) %>% 
  arrange(count_type, loc_type)

df_rq2a_counts$count <- as.numeric(df_rq2a_counts$count)
df_rq2a_counts$count_type <- factor(df_rq2a_counts$count_type, levels = rev(c('all_domestic', 'research_univ_instate', 'research_univ_outofstate', 'regional_univ_instate', 'regional_univ_outofstate')))
df_rq2a_counts$loc_type <- factor(df_rq2a_counts$loc_type, levels = rev(c('Domestic', 'International')))

df_rq2a_counts %>% 
  ggplot(aes(x = count_type, y = count, fill = loc_type, width = 0.6)) +
  geom_bar(position = 'stack', stat = 'identity', alpha = 0.6) +
  geom_text(aes(y = if_else(count_type != 'regional_univ_outofstate', count, count * 7), label = prettyNum(count, ',')), color = '#555555', size = 2, position = position_stack(vjust = 0.5)) +
  xlab('') + ylab('') +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 1968000)) +
  scale_fill_brewer(palette = 'YlGnBu', name = 'Locale') +
  theme(
    axis.text.x = element_blank(),
    legend.position = 'top'
  ) +
  guides(fill = guide_legend(reverse = T)) +
  coord_flip()
```

```{r}
create_rq2a_figure <- function(categories, legend_title) {
  df_rq2a_fig <- df_rq2a %>% 
    filter(row_subj %in% categories) %>% 
    select(row_subj, all_domestic, research_univ_instate, regional_univ_instate, research_univ_outofstate, regional_univ_outofstate) %>% 
    pivot_longer(-row_subj, names_to = 'pct_type', values_to = 'pct')
  
  df_rq2a_fig$pct_type <- factor(df_rq2a_fig$pct_type, levels = rev(c('all_domestic', 'research_univ_instate', 'regional_univ_instate', 'research_univ_outofstate', 'regional_univ_outofstate')))
  df_rq2a_fig$row_subj <- factor(df_rq2a_fig$row_subj, levels = rev(categories))
  
  df_rq2a_fig %>% 
    ggplot(aes(x = pct, y = pct_type, fill = row_subj, width = 0.6)) +
    geom_bar(position = 'stack', stat = 'identity', alpha = 0.6) +
    geom_text(aes(x = pct, label = ifelse(pct > 1, round(pct, 0), '')), color = '#555555', size = 2, position = position_stack(vjust = 0.5)) +
    xlab('') + ylab('') +
    scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 101)) +
    scale_fill_brewer(palette = 'YlGnBu', direction = -1, name = legend_title) +
    theme(
      axis.text.x = element_blank()
    ) +
    guides(fill = guide_legend(reverse = T))
}
```


### Racial Characteristics

Figure \@ref(fig:prospects-race) presents the racial characteristics of all domestic prospects resulting from the 388 purchased orders by in-state versus out-of-state for research and master's university purchases. Race/ethnicity of prospects is collected from the College Board's voluntary demographic questionnaire completed by students when taking the SAT; therefore, we report racial characteristics as self-identified and include the percentage of students that did not report their race/ethnicity. About 38% of all domestic prospects self-identified as White, 23% as Latinx, 16% as Asian, 6% as Black, 5% as Multiracial, and 13% did not report their race/ethnicity. 

Out-of-state prospects purchased tended to be more White and Asian than in-state prospects purchased, although a larger percentage of in-state prospects did not report their race/ethnicity. For example, when universities in the study made order purchases for prospects residing in different states than where their campus is located, these lists resulted in prospect lists made up of 43% White students, 22% Asian students, 19% Latinx students, 6% Black, 6% multiracial, and 4% no response. In comparison, purchases for prospects residing in the same state as the institution's campus results in lists made up of 34% White students, 11% Asian, 25% Latinx, 5% Black, 4% multiracial, and 19% of students that did not report their race/ethnicity. While out-of-state prospect lists included a larger proportion of White and Asian students, these orders also include a critical mass of Native American students (N=7,885 DOUBLE CHECK THIS) that can be glossed over when only looking at overall proportions.

The differences in the racial characteristics of in-state versus out-of-state prospects are likely also a function of purchases made by research versus master's universities. While research universities made more out-of-state than in-state prospect purchases, the differences in the racial characteristics of both groups were relatively small in comparison to purchases by master's universities. For example, White students made up 43% and 40% of out-of-state and in-state prospect lists purchased by research universities, respectively. In comparison, White students made up 45% of out-of-state prospect lists and only 30% of in-state prospect lists purchased by master's universities. However, purchases by master's universities also included a much larger proportion of students that did not report their race/ethnicity. 

```{r prospects-race, fig.height = 2.3, fig.cap = 'Prospects purchased by race'}
create_rq2a_figure(c('Pct White', 'Pct Black', 'Pct Latinx', 'Pct Asian', 'Pct NH/PI', 'Pct AI/AN', 'Pct Multiracial', 'Pct Race-No Response', 'Pct Race-Missing'), 'Race/ethnicity')
```


### Economic Characteristics

Figure \@ref(fig:prospects-income) presents the average median income of the zip code where prospects live by in-state versus out-of-state status for research and master's university purchases. Purchased prospects, across all orders by the 12 universities in the study, live in areas with an average median household income of \$92,000. 

Overall, Figure \@ref(fig:prospects-income) shows out-of-state prospects tended to live in more affluent areas than in-state prospects. Across all institution types, when universities in the study made order purchases for prospects residing in different states than where their campus is located, these lists resulted in prospects that live in areas where the average median household income is \$100,000. In comparison, purchases for prospects residing in the same state as the institution's campus resulted in prospects that live in areas where the average median household income is \$87,000.   

This disparity is also likely driven by several differences across purchases by research versus master's universities. For example, out-of-state prospects purchased by research universities live in areas where the average median household income is \$101,000, whereas in-state prospects purchased live in areas with a \$91,000. However, the opposite pattern is evident for purchases by master's universities. Out-of-state prospects purchased by master's universities on average live in less affluent areas (\$69,000 median household income) than in-state prospects ($84,000 median household income). 

```{r prospects-income, fig.height = 2.5, fig.cap = 'Prospects purchased by income'}
df_rq2a_income <- df_rq2a %>% 
  filter(row_subj == 'Median Household Income (mean)') %>% 
  select(all_domestic, in_state, out_of_state, research_univ_instate, research_univ_outofstate, regional_univ_instate, regional_univ_outofstate) %>% 
  t()

df_rq2a_income <- data.frame(df_rq2a_income, row.names = rownames(df_rq2a_income)) %>% 
  rownames_to_column(var = 'count_type') %>% 
  dplyr::rename(count = df_rq2a_income)

df_rq2a_income$count_type <- factor(df_rq2a_income$count_type, levels = rev(c('all_domestic', 'in_state', 'out_of_state', 'research_univ_instate', 'research_univ_outofstate', 'regional_univ_instate', 'regional_univ_outofstate')))

df_rq2a_income %>% 
  ggplot(aes(x = count, y = count_type, width = 0.6)) +
  geom_bar(stat = 'identity', fill = '#7FCDBB', alpha = 0.6) +
  geom_text(aes(x = count + 800, label = str_c('$', round(count / 1000, 0), 'K')), color = '#555555', size = 2, hjust = 0) +
  xlab('') + ylab('') +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 110000)) +
  theme(
    axis.text.x = element_blank(),
    legend.position = 'top'
  ) +
  guides(fill = guide_legend(reverse = T))
```

### High Schools Attended

Given some of the College Board products link individual prospects to high schools for services like high school segment clusters, we are able to analyze some of the characteristics of high schools purchased prospects attend.

Figure \@ref(fig:prospects-hs) presents school type for purchased prospects by in-state versus out-of-state status for research and master's university purchases. Overall, 82% of prospects purchased attend public high schools, 9% attend private schools, and 9% did not report their high school. While these overall proportions are comparable to national averages, there are several differences across in-state versus out-of-state purchases by research and master's universities. For research universities, students attending private high schools made up a greater share of out-of-state prospect lists (12%) than in-state lists purchases (7%). Student list purchases by master's universities also exhibited this patter, where private high school students made up 10% of out-of-state prospects versus 6% of in-state prospects purchased.

```{r prospects-hs, fig.height = 2.3, fig.cap = 'Prospects purchased by school type'}
create_rq2a_figure(c('Pct Public', 'Pct Private', 'Pct School Unknown'), 'School type')
```

### International Prospects

Nearly 100,000 of the 2 Million prospects purchased were international students. Table \@ref(tab:prospects-intl) presents the countries from which these prospects were purchased, with XYZ representing the total number of prospects purchased by country. The top ten countries, which account for more than 60% of international prospects purchased across the 388 orders, include India (18%), China (10%), Singapore (6%), South Korea (6%), Canada (5%), United Arab Emirates (5%), Pakistan (4%), Taiwan (3%), Saudi Arabia (3%), and Thailand (3%).

```{r prospects-intl}
df_int %>% 
  mutate(
    stu_country = str_to_title(stu_country),
    n = prettyNum(n, ','),
    pct = str_c(pct, '%')
  ) %>% 
  head(10) %>% 
  kable(booktabs = T, col.names = c('Country', '# prospects', '% prospects'), align = rep('c', 3), caption = 'Prospects purchased by international country') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(position = 'center')
```

## Filter Criteria and Characteristics of Prospects

We analyze the relationship between filter criteria and the characteristics of purchased prospects in two different ways. First, we analyze prospect characteristics (e.g., race/ethnicity, income, in-state versus out-of-state) across individual filters to understand broad patterns. Second, we analyze prospect characteristics across common combinations of filters. Here we use selected universities, purchases and/or localities that convey commonly observed or thematically important patterns across combinations of filters. We also contextualize the characteristics of purchased prospects by showing the characteristics of one or more comparison groups based on the selected examples.

### Prospect Characteristics Across Individual Filters

Table \@ref(tab:prospects-filters) presents the characteristics of prospects by individual filters. For each column, averages are reported across all prospects that were purchased via orders using the specified column filter, which includes orders that used the specified filter in combination with other filters. ^[Given we present all prospects across individual filters that are used in combination with others, total number of prospects summed across columns will exceed our grand total of 1,967,352 prospects]. 

Focusing on the racial characteristics of prospects, student lists with the largest percentages of White and Asian prospects result when orders use PSAT, gender, segment, or CBSA filters. For example, orders that specify a gender filter result in prospect lists that are less than 10% Black, Latinx, and/or Native American. This pattern is consistent in prospect lists that use segment or CBSA filters, although the disparity is not as large for orders using a PSAT filter (30% Black, Latinx, Native America).  On the other hand, orders that filter by specifying particular race/ethnicity groups result in lists that have fewer White and Asian prospects and greater proportions of Black, Latinx, Native American, and multiracial prospects. This coincides with descriptive findings above that suggest more than half of all orders using a race/ethnicity filter specified Black, Native American, and/or Latinx prospects.

```{r prospects-filters}
df_rq3 %>% 
  mutate_if(is.numeric, round, 0) %>% 
  mutate_each(funs(prettyNum(., big.mark = ','))) %>% 
  kable(booktabs = T, col.names = c('', 'All domestic', 'GPA', 'PSAT', 'SAT', 'HS rank', 'Race', 'Gender', 'Zip code', 'State', 'Segment', 'CBSA'), align = c('l', rep('c', 11)), caption = 'Characteristics of prospects by filters') %>% 
  row_spec(0, bold = T) %>%
  kable_styling(latex_options = 'scale_down')
```

Similar disparities are evident across the economic characteristics of prospect lists by filters used. Orders using PSAT, gender, segment, or CBSA filters result in prospect lists with the largest average median household incomes. Orders using a CBSA filter showcase the upper extreme of this pattern, resulting in lists where the average prospect lived in a zipcode where the median household income \$113,000. Similarly, orders using race/ethnicity filters showcased the lower extreme. When universities purchased orders that filtered for specific race/ethnicity groups, the resulting lists included prospects that lived in zip codes where the average median household income was less than $85,000. 

Not surprisingly, orders using geographic filters result in specific patterns of in-state versus out-of-state prospects. However, analyzing the residency status of prospect lists across filters can help us develop insights into how specific filters are used to target prospects geographically. For example, orders using segment and CBSA filters are likely used for targeting out-of-state students, as the use of these filters result in prospect lists made up of 85% and 96% out-of-state prospects, respectively. However, orders filtering for prospects within specific state(s) result in list that are nearly equal proportions of out-of-state and in-state students. Coinciding with descriptive statistics detailed above and data limitations (i.e., we only received zip codes used to filter order lists by two master's universities in our sample), nearly 98% of prospects resulting from orders using a zip code filter were in-state students. Similar to disparities in racial and economic characteristics of prospects, orders using a gender filter also resulted in geographical disparities (94% out-of-state versus 6% in-state).  

Lastly, Table \@ref(tab:prospects-filters) shows the difference in proportions of prospects that attend public versus private schools does not change significantly across filters used. For example, orders that specify a CBSA result in student lists where on average 14% of prospects attend private schools, which is the maximum proportion across all filters. In comparison, orders that use race/ethnicity or state filters result in students lists with the minimum proportion of prospects attending private schools (7%).


### Prospect Characteristics Across Combinations of Filters

### In-State Order Combinations

We begin analyzing the characteristics of prospects across some of the most common combination of filters. Many of the orders in our analysis filtered by high school graduation class, PSAT scores, GPA, and zip code. Figure \@ref(fig:orders-zip) and analyses above suggest orders using this combination of filters were made by master's universities to identify in-state and regional prospects. We "zoom" into orders by one of these master's universities, Texas A & M University- Texerkana, in order analyze in-depth patterns in the racial and economic characteristics of prospects that result from this combination of filters. 

Texas A & M University- Texerkana made 65 orders using graduation class, PSAT scores, GPA, and zip code filters. These orders targeted 2019-2022 high school graduating classes with minimum PSAT scores ranging from 920-1300 and maximum SAT scores ranging from 970-1450. The university also filtered for prospects with GPAs ranging from a low of C+ to a high of A+. Lastly, prospects were also filtered using a series of 3-digit zip codes that included both in-state and neighboring state zip codes. 

<!-- Nine of the 65 orders targeted students living in Texas (Greenville, Denton, Palestine, Lufkin, and Tyler areas), although orders also included neighboring state zip codes in Arkansas (Camden and Hot Springs areas), Oklahoma (Durant area), and Louisiana (Monroe and Shreveport areas). Another 13 orders targeted these same areas in addition to prospects in the Conroe, Richmond, and Pasadena areas of Texas. Twenty-seven orders focused on targeting prospects in zip codes for the Texerkana (Texas and Arkansas), Dallas, Fort-Worth, and Long View areas. Lastly, 16 orders targeted prospects only in the Houston, Conroe, Richmond and Pasadena areas.  -->

For each three-digit zip code used as an order filter, we compare the average racial and economic characteristics of the resulting purchased prospects to the zip code's population of 15-19 year-olds. We select the zip code population as the comparison group for purchase prospects filtered by graduation class, PSAT scores, GPA, and zip code filters for various reasons. First, the university included a three-digit zip code filter which encapsulates all students living within in a specified area (usually a City or County), which should hypothetically cast a wider, more equitable net than filtering explicitly by 5-digit zip codes. However, we analyze whether this wider net is compromised when it is used along with test scores and GPA. Secondly, master's universities are like to serve regional student markets, rather than the entire state where they are located. Therefore, we use a filtered zip code's population as a comparison group for prospects purchased within that zip code rather than all zip codes in the state from which prospects were not purchased from. 

For example, the three-digit zip code 752 was included in 27 of the 65 orders that filtered across graduation class, PSAT scores, GPA and zip code. The 49 five-digit zip codes nested within the three-digit 752 zip code includes communities across the Dallas metropolitan area (see Figure X). The student lists for these orders resulted in 8,707 purchased prospects living in one of the 47 five-digit zip codes. About 40% of purchased prospects identified as White, 39% as Latinx, 8% Black, 5% Asian, and 3% multiracial. In comparison, the population of 15-19 year olds in these 49 five-digit zip codes are 24% White, 43% Hispanic, 20% Black, 3% Asian, and 3% multiracial.

Figure \@ref(fig:texasam-race) presents the average percentage point difference between the racial/ethnic composition of students lists and of the 15-19 year old population across all zip codes filtered by the master's university in this analysis. For example, Zip Code 752 in Figure \@ref(fig:texasam-race) shows a 16 percentage point difference between White prospects purchased living in the zip code and the overall percentage of White 15-19 year olds living in the zip code (40%- 24% = 16 percentage points), suggesting White prospects are overrepresented in purchased lists relative to the population of their home zip code. Similarly, the figure shows a -12 percentage point difference between the Black prospects purchased from the zip code and the percentage of Black 15-19 year olds living in the zip code (8% - 20% = -23 percentage points), suggesting Black prospects are underrepresented in purchased lists relative to the population of their home zip code.

```{r texasam-race, fig.height = 4, fig.cap = 'Texas A&M purchases by zip code and race'}
table_texasam_zip$stu_race_cb <- factor(table_texasam_zip$stu_race_cb, levels = rev(c('AIAN', 'Asian', 'Black', 'Latinx', 'Multiracial', 'White')))

table_texasam_zip %>% 
  ggplot(aes(x = ppt_diff_stu_pop, y = zip_3digit, fill = stu_race_cb)) + 
  geom_bar(position = 'dodge', stat = 'identity') +
  scale_fill_brewer(palette = 'Set2', direction = -1, name = 'Race/ethnicity') +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), breaks = seq(-50, 40, 10), limits = c(-50, 45)) +
  scale_y_discrete(limits = rev) +
  xlab('Percentage point difference') + ylab('3-digit zip code') +
  guides(fill = guide_legend(reverse = T))
```

Overall, Figure \@ref(fig:texasam-race) suggests prospect lists from orders that filtered using graduation class, PSAT scores, GPA, and zip code tend to be more White and Asian and less Black and Latinx relative to the population of 15-19 year olds from zip codes filtered by. The overepresentation of White prospects in comparison to zip code populations ranged from 2 to 36 percentage points for 11 of the 23 zip codes filtered by, whereas three zip codes had proportional representation (0 percetage point difference). The remaining 9 zip codes had an underrepresentation of White prospects, where eight orders ranged from 1 to 6 percentage points and one order had -21 percentage points. The overrepresentation of Asian prospects purchased across the 23 zip codes ranged from 1 to 17 percentage points.

Black prospects were underrepresented relative to zip code populations across all zip codes used and in the greatest magnitude across all racial/ethnic groups. The underrepresentation of Black prospects purchased across the 23 zip codes ranged from 2 to 47 percentage points. Latinx students were also underrepresented across 12 of the 23 zip codes, although the magnitude was not as large as (ranging from 1 to 10 percentage points). Three of the zip codes filtered by had proportional representation of Latinx students (0 percentage point difference), whereas the remaining zip codes had an overrepresentation ranging from 1 to 4 percentage points. 

Economic disparities are also evident when we compare the average median income of prospects relative to the average median household of the zip code population. Figure \@ref(fig:texasam-income)  presents the difference in average median household income between prospects (measured at the 5-digit zip code level) and the average median household income across all nested 5-digit zip codes within the 3-digit filters used. Because both prospects' and population income is measured at the zip code level across 5- versus 3-digits, a disparity indicates more prospects living in affluent 5-digit zip codes were purchased than the average median household income across all 5-digit codes within the 3-digit filter. 

Figure \@ref(fig:texasam-income) shows student lists resulting from 22 of the 23 zip code filters included more affluent prospects than the average population of those zip codes. This disparity was largest for prospects purchased from 774 zip codes (communities within Richmond, Texas), which had an average median income nearly $40,000 greater than the average median income of the population across all nested 774 zip codes. Prospects purchased from 758 zip codes (communities within Palestine, Texas) were the only across all filters to have an average median income less than the population across all nested zip codes (\$43,000 versus \$50,000). 

```{r texasam-income, fig.height = 4, fig.cap = 'Texas A&M purchases by zip code and income'}
table_texasam_zip_inc %>% 
  mutate(inc_diff_stu_pop = stu_mean_inc - pop_med_inc) %>% 
  ggplot(aes(x = inc_diff_stu_pop, y = zip_3digit, width = 0.3)) + 
  geom_bar(position = 'dodge', stat = 'identity', fill = '#7FCDBB', alpha = 0.6) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(-10001, 40001), labels = label_number(suffix = 'K', scale = 1e-3)) +
  scale_y_discrete(limits = rev) +
  xlab('Income difference ($)') + ylab('3-digit zip code') +
  guides(fill = guide_legend(reverse = T))
```

<!-- COMPLETE IN JANUARY Another common combination of filters used across orders include the same academic filters (i.e., PSAT scores and GPA) but geographically filtered by specific states and filtered for specific race/ethnicity groups. Some of these orders were made by research universities in the study -->


### Out-of-State Order Combinations

Other common combinations of filters were used by research universities in the study to target out-of-state prospects. Some of these orders filtered by graduation class, state, CBSA, segment, SAT or PSAT, and GPA. We "zoom" into orders by The University of Illinois at Urbana-Champaign in order to analyze in-depth patterns in the racial and economic characteristics of prospects that result from this combination of filters.

The University of Illinois at Urbana-Champaign made eight orders using graduation class, state, CBSA, segment, SAT or PSAT, and GPA. These orders targeted 2019-2023 high school graduating classes with minimum PSAT/SAT scores ranging from 1220-1240 and maximum PSAT/SAT scores of 1450. The university also filtered for prospects with GPAs ranging from a low of B- to a high of A+. Prospects were also geographically filtered across State/CBSAs and segments. For States/CBSA, the university filtered across some of the largest, most populated metropolitan areas of the country (including but not limited to Atlanta, New York, Philadelphia, Boston, Washington D.C., Detroit, Phoenix, Miami, Orlando, Baltimore, Denver, Raleigh). As described above, segment filters across orders used both neighborhood and high school clusters. These eight orders filtered for neighborhood clusters 51 (with sll high school clusters), 53 (with high school cluster 70), 58 (all high schools), 60 (with high school clusters 65,70,79),  61 (with high school cluster 65), 63 (with high school clusters 68, 70), 69 (with high school clusters 65, 79), 70 (with high school clusters 65, 68, 70, 75), 73 (with all high schools), 78 (with high school cluster 66). Orders also included all high school categorized under high school cluster 79. 

We analyze orders by the University of Illinois at Urbana-Champaign that use these filters across several metropolitan areas by comparing the average racial and economic characteristics of the resulting purchased prospects to the metropolitan areas' overall population' of public high school students. We select the population of public high school students within the metropolitan area as a comparison group for several reasons. First, similar to our analysis of zip code filters above, the university included entire metropolitan areas as filters that should hypothetically provide an equitable opportunity for all prospects living in the area to be included in student lists purchased by the university. However, the combination of segment and additional academic filters may result in disparities across which prospects are included in comparison to the average population of the metropolitan area. 

Figure \@ref(fig:metro-race) shows the racial/ethnic characteristics of purchased prospects versus the population of students attending public high schools in three metropolitan areas that were included across all eight orders by the University of Illinois at Urbana-Champaign using graduating lass, state, CBSA, segment, SAT or PSAT, and GPA filters. For example, the top panel shows the resulting student lists for University of Illinois at Urbana-Champaign that targeted prospects within the Los Angeles metropolitan area using these filters. The brown bars indicate the students lists for these orders resulted in 18,420 purchased prospects living in the metropolitan area. About 30% of purchased prospects identified as White, 49% as Asian, 1% as Black, 9% as Latinx, and 7% as multiracial. In comparison, the blue bars in the figure indicate the population of public high school students in the Los Angeles metropolitan area are 18% White, 13% Asian, 6% Black, 60% Latinx, and 3% Multiracial.

```{r metro-race, fig.height = 5, fig.cap = 'Metro area purchases by race'}
fig_rq3_segment_race_inc %>% 
  select(-income, -tot_students) %>% 
  pivot_longer(c(-metro, -population), names_to = 'race', values_to = 'pct') %>% 
  ggplot(aes(x = race, y = pct, fill = population, width = 0.6)) + 
  geom_bar(position = position_dodge2(width = 0.7, reverse = T), stat = 'identity') +
  scale_fill_manual(values = color_palette, name = 'Population') +
  scale_y_continuous(labels = function(x) paste0(x, '%')) +
  xlab('') + ylab('') +
  theme(
    strip.background = element_blank(),
    strip.text = element_text(face = 'bold')
  ) +
  guides(fill = guide_legend(reverse = T)) +
  facet_wrap(~ metro, ncol = 1)
```

Across orders using graduation class, segment, SAT or PSAT, and GPA filters within the Los Angeles, Philadelphia, and New York Metropolitan areas, prospect lists resulted in higher percentages of White and Asian students relative to the population of public high school students within each metropolitan area. The overrepresentation of White prospects in student lists relative to the population of public high school students ranged from 12 to 17 percentage points across the three metropolitan areas. Purchased prospects within the Los Angeles metropolitan areas exemplified the largest disparity for Asian students, with 49% of purchased prospects identifying as Asian relative to the 13% of public high school students identifying as Asian within the metropolitan area (a 36 percentage point difference). 

Figure \@ref(fig:metro-race) shows Black and Latinx prospects were underrepresented relative to public school students across all three metropolitan areas. Orders made within the Philadelphia metropolitan area exemplify the largest magnitude in this disparity for Black students, with Black students making up less than 2% of purchased prospects while making up more than 25% of all public high school students in the metropolitan area. The underrepresentation of Black prospects in comparison to public high school students was 16 percentage points for the New York and 3 percentage points for the Los Angeles metropolitan areas. On the other hand, the Los Angeles metropolitan area exemplified the largest disparity for Latinx students (9% Latinx purchased prospects versus 60% Latinx public high school students).  The underrepresentation of Latinx prospects in comparison to public high school students was 8 percentage points for the Philadelphia and 24 percentage points for the New York metropolitan areas.


```{r metro-income, fig.height = 2.5, fig.cap = 'Metro area purchases by income'}
fig_rq3_segment_race_inc %>% 
  mutate(
    population = recode_factor(population, 'Prospects Purchased' = 'Prospects purchased', 'Public HS Students' = 'All Metro Households')) %>%
  select(metro, population, income) %>% 
  ggplot(aes(x = income, y = metro, fill = population, width = 0.6)) + 
  geom_bar(position = position_dodge(width = 0.7), stat = 'identity') +
  scale_fill_manual(values = color_palette, name = 'Population') +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, 131000), labels = label_number(suffix = 'K', scale = 1e-3)) +
  xlab('Income ($)') + ylab('Metro area') +
  guides(fill = guide_legend(reverse = T))
```


Figure \@ref(fig:metro-income) presents the average median household income of purchased prospects (taken at the 5-digit zip code level) in comparison to the median household income of the entire metropolitan area. For example, the median income across all households in the Philadelphia metropolitan area is \$75,000, whereas prospects living within the metropolitan area purchased by the University of Illinois at Urbana-Champaign had an average median household income of \$114,000. Prospects purchased tended to have higher median average household incomes than the average across all households within the Los Angeles and New York metropolitan areas also. The difference was nearly \$50,000 for New York and \$30,000 for Los Angeles. 











# References

<div id="refs"></div>



